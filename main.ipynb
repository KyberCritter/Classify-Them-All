{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Pokemon Types from Images and Statistics\n",
    "\n",
    "Scott Ratchford"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set paths to data files and directories\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "DATA_PATH = os.path.join(os.getcwd(), \"data\")\n",
    "PKMN_STATS_PATH = os.path.join(DATA_PATH, \"pokemon_stats.csv\")\n",
    "IGNORED_PKMN_PATH = os.path.join(DATA_PATH, \"ignored_pokemon.csv\")\n",
    "IMAGES_DIR_PATH = os.path.join(DATA_PATH, \"pokemon_images\")\n",
    "\n",
    "RNG_SEED = 151\n",
    "\n",
    "TEST_SIZE = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PKMN: 1023\n",
      "PKMN Stats: ['Number', 'Name', 'Type 1', 'Type 2', 'Total', 'HP', 'Attack', 'Defense', 'Sp. Atk', 'Sp. Def', 'Speed', 'Generation', 'Legendary']\n",
      "Ignored PKMN: ['Giratina', 'Darmanitan', 'Hoopa']\n",
      "PKMN after dropping ignored: 1022\n"
     ]
    }
   ],
   "source": [
    "# Import in-game statistics dataset\n",
    "pkmn_stats = pd.read_csv(PKMN_STATS_PATH, encoding=\"utf-8\")\n",
    "print(f\"PKMN: {pkmn_stats.shape[0]}\")\n",
    "print(f\"PKMN Stats: {list(pkmn_stats.columns)}\")\n",
    "\n",
    "# Drop rows that contain Pokemon to be ignored\n",
    "ignored_pkmn = pd.read_csv(IGNORED_PKMN_PATH, encoding=\"utf-8\", delimiter=\"\\t\")\n",
    "ignored_pkmn = ignored_pkmn.dropna(axis=0, subset=[\"Number\"])\n",
    "print(f\"Ignored PKMN: {ignored_pkmn[\"Name\"].tolist()}\")\n",
    "\n",
    "pkmn_stats = pkmn_stats[~pkmn_stats[\"Number\"].isin(ignored_pkmn[\"Number\"])]\n",
    "print(f\"PKMN after dropping ignored: {pkmn_stats.shape[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = pkmn_stats.copy()\n",
    "\n",
    "# Drop columns that provide too much information about the Pokemon\n",
    "tmi_cols = [\"Name\", \"Generation\"]\n",
    "X = X.drop(labels=tmi_cols, axis=1)\n",
    "\n",
    "# Drop other columns\n",
    "drop_cols = [\"Type 2\", ]\n",
    "X = X.drop(labels=drop_cols, axis=1)\n",
    "\n",
    "# Drop columns containing target information\n",
    "target_cols = [\"Type 1\", ]\n",
    "y = pkmn_stats[target_cols].copy()\n",
    "X = X.drop(labels=target_cols, axis=1)\n",
    "\n",
    "# Encode type strings (to ints)\n",
    "type_label_encoder = LabelEncoder()\n",
    "y[\"Type 1\"] = type_label_encoder.fit_transform(y[\"Type 1\"])\n",
    "y[\"Type 1\"] = y[\"Type 1\"].astype(dtype=int)\n",
    "# y_train[\"Type 2\"] = type_label_encoder.fit_transform(y_train[\"Type 2\"])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=TEST_SIZE, random_state=RNG_SEED)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Coding\\ST-545-Project\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:805: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 17\u001b[39m\n\u001b[32m      7\u001b[39m knn_hyperparameters = {\n\u001b[32m      8\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mn_neighbors\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mrange\u001b[39m(\u001b[32m3\u001b[39m, \u001b[32m11\u001b[39m),\n\u001b[32m      9\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mleaf_size\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mrange\u001b[39m(\u001b[32m10\u001b[39m, \u001b[32m41\u001b[39m),\n\u001b[32m   (...)\u001b[39m\u001b[32m     12\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33malgorithm\u001b[39m\u001b[33m\"\u001b[39m: (\u001b[33m\"\u001b[39m\u001b[33mkd_tree\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mball_tree\u001b[39m\u001b[33m\"\u001b[39m, ),\n\u001b[32m     13\u001b[39m }\n\u001b[32m     15\u001b[39m knn_clf = GridSearchCV(knn_stats_model, knn_hyperparameters, n_jobs=-\u001b[32m1\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m knn_stats_model = \u001b[43mknn_clf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m.\u001b[49m\u001b[43mravel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Coding\\ST-545-Project\\.venv\\Lib\\site-packages\\sklearn\\base.py:1389\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1382\u001b[39m     estimator._validate_params()\n\u001b[32m   1384\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1385\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1386\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1387\u001b[39m     )\n\u001b[32m   1388\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1389\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Coding\\ST-545-Project\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1024\u001b[39m, in \u001b[36mBaseSearchCV.fit\u001b[39m\u001b[34m(self, X, y, **params)\u001b[39m\n\u001b[32m   1018\u001b[39m     results = \u001b[38;5;28mself\u001b[39m._format_results(\n\u001b[32m   1019\u001b[39m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[32m   1020\u001b[39m     )\n\u001b[32m   1022\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[32m-> \u001b[39m\u001b[32m1024\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1026\u001b[39m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[32m   1027\u001b[39m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[32m   1028\u001b[39m first_test_score = all_out[\u001b[32m0\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mtest_scores\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Coding\\ST-545-Project\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1571\u001b[39m, in \u001b[36mGridSearchCV._run_search\u001b[39m\u001b[34m(self, evaluate_candidates)\u001b[39m\n\u001b[32m   1569\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[32m   1570\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1571\u001b[39m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Coding\\ST-545-Project\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:970\u001b[39m, in \u001b[36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[39m\u001b[34m(candidate_params, cv, more_results)\u001b[39m\n\u001b[32m    962\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.verbose > \u001b[32m0\u001b[39m:\n\u001b[32m    963\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[32m    964\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[33m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[33m candidates,\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    965\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[33m fits\u001b[39m\u001b[33m\"\u001b[39m.format(\n\u001b[32m    966\u001b[39m             n_splits, n_candidates, n_candidates * n_splits\n\u001b[32m    967\u001b[39m         )\n\u001b[32m    968\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m970\u001b[39m out = \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    971\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    972\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    973\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    974\u001b[39m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    975\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    976\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    977\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    978\u001b[39m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    979\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    980\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    981\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    982\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    983\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    984\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplitter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    985\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    986\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    988\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) < \u001b[32m1\u001b[39m:\n\u001b[32m    989\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    990\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mNo fits were performed. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    991\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mWas the CV iterator empty? \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    992\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mWere there no candidates?\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    993\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Coding\\ST-545-Project\\.venv\\Lib\\site-packages\\sklearn\\utils\\parallel.py:77\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m     72\u001b[39m config = get_config()\n\u001b[32m     73\u001b[39m iterable_with_config = (\n\u001b[32m     74\u001b[39m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[32m     75\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[32m     76\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m77\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Coding\\ST-545-Project\\.venv\\Lib\\site-packages\\joblib\\parallel.py:2007\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   2001\u001b[39m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[32m   2002\u001b[39m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[32m   2003\u001b[39m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[32m   2004\u001b[39m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[32m   2005\u001b[39m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[32m-> \u001b[39m\u001b[32m2007\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Coding\\ST-545-Project\\.venv\\Lib\\site-packages\\joblib\\parallel.py:1650\u001b[39m, in \u001b[36mParallel._get_outputs\u001b[39m\u001b[34m(self, iterator, pre_dispatch)\u001b[39m\n\u001b[32m   1647\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[32m   1649\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backend.retrieval_context():\n\u001b[32m-> \u001b[39m\u001b[32m1650\u001b[39m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m._retrieve()\n\u001b[32m   1652\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[32m   1653\u001b[39m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[32m   1654\u001b[39m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[32m   1655\u001b[39m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[32m   1656\u001b[39m     \u001b[38;5;28mself\u001b[39m._exception = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Coding\\ST-545-Project\\.venv\\Lib\\site-packages\\joblib\\parallel.py:1762\u001b[39m, in \u001b[36mParallel._retrieve\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m._jobs) == \u001b[32m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[32m   1760\u001b[39m     (\u001b[38;5;28mself\u001b[39m._jobs[\u001b[32m0\u001b[39m].get_status(\n\u001b[32m   1761\u001b[39m         timeout=\u001b[38;5;28mself\u001b[39m.timeout) == TASK_PENDING)):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[43mtime\u001b[49m\u001b[43m.\u001b[49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1763\u001b[39m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m   1765\u001b[39m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[32m   1766\u001b[39m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[32m   1767\u001b[39m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Create the KNN model for in-game statistics\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "knn_stats_model = KNeighborsClassifier()\n",
    "# hyperparameters to try\n",
    "knn_hyperparameters = {\n",
    "    \"n_neighbors\": range(3, 11),\n",
    "    \"leaf_size\": range(10, 41),\n",
    "    \"p\": range(1, 10),\n",
    "    \"weights\": (\"distance\", \"uniform\", ),\n",
    "    \"algorithm\": (\"kd_tree\", \"ball_tree\", ),\n",
    "}\n",
    "\n",
    "knn_clf = GridSearchCV(knn_stats_model, knn_hyperparameters, n_jobs=-1)\n",
    "\n",
    "knn_stats_model = knn_clf.fit(X_train, y_train.values.ravel())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.09268292682926829, Test Error: 0.9073170731707317\n",
      "Confusion Matrix:\n",
      "[[5 2 0 0 0 0 2 0 0 2 0 0 3 3 0 0 2 3]\n",
      " [0 0 0 0 0 2 1 0 0 0 1 0 1 0 0 0 1 1]\n",
      " [1 1 1 0 1 0 1 0 0 2 0 0 0 1 0 0 1 2]\n",
      " [2 1 0 0 0 3 2 1 0 1 0 0 1 0 0 0 0 4]\n",
      " [0 0 0 0 1 0 1 0 1 3 0 0 3 0 1 0 1 1]\n",
      " [1 0 0 0 1 0 0 0 0 1 1 0 3 1 0 0 0 0]\n",
      " [0 1 0 1 0 0 1 0 1 1 0 1 1 1 0 0 0 3]\n",
      " [0 2 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 3 0 2 0 1 2]\n",
      " [1 1 1 0 0 0 3 0 0 1 2 0 1 0 1 1 0 7]\n",
      " [2 0 0 0 0 2 0 0 0 1 1 1 1 0 0 1 1 0]\n",
      " [1 1 2 0 0 0 0 0 0 0 0 0 0 0 1 0 1 1]\n",
      " [3 3 1 0 0 0 0 0 0 4 2 0 2 3 0 0 0 2]\n",
      " [1 0 0 0 0 0 0 0 0 1 1 0 0 1 0 1 0 2]\n",
      " [0 2 1 1 0 0 1 0 2 2 0 1 1 0 3 1 0 1]\n",
      " [0 1 0 0 0 1 1 0 0 0 1 0 0 1 1 0 0 1]\n",
      " [0 1 0 1 0 0 0 0 0 0 1 1 0 0 0 1 2 0]\n",
      " [0 0 0 0 1 0 1 1 0 3 0 0 1 2 2 2 1 1]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "knn_pred = knn_clf.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, knn_pred)\n",
    "conf_matrix = confusion_matrix(y_test, knn_pred)\n",
    "print(f\"Accuracy: {accuracy}, Test Error: {1-accuracy}\")\n",
    "print(f\"Confusion Matrix:\\n{conf_matrix}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Match test data with original data to find names and types\n",
    "pkmn_stats.reset_index()\n",
    "knn_pred_df = pd.DataFrame(knn_pred, columns=[\"Type 1 Prediction\"])\n",
    "knn_pred_df[\"Type 1 Prediction\"] = type_label_encoder.inverse_transform(knn_pred_df[\"Type 1 Prediction\"])\n",
    "knn_pred_df.reset_index()\n",
    "\n",
    "# join knn pred with X_test on index\n",
    "x_test_and_knn_pred = pd.merge(X_test, knn_pred_df, how=\"inner\", left_index=True, right_index=True, validate=\"1:1\")\n",
    "# join that result to pkmn_stats to find predicted type\n",
    "join_on = [\"Number\", \"Total\", \"HP\", \"Attack\", \"Defense\", \"Sp. Atk\", \"Sp. Def\", \"Speed\", \"Legendary\"]\n",
    "rejoined_data = pd.merge(pkmn_stats, x_test_and_knn_pred, how=\"inner\", left_on=join_on, right_on=join_on, validate=\"1:1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "IMG_TEST_DIR = os.path.join(os.getcwd(), \"data\", \"pokemon_images\", \"test\")\n",
    "IMG_TRAIN_DIR = os.path.join(os.getcwd(), \"data\", \"pokemon_images\", \"train\")\n",
    "\n",
    "PKMN_COLORS_PATH = os.path.join(os.getcwd(), \"pokemon_colors.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import webcolors\n",
    "from webcolors._definitions import _get_hex_to_name_map\n",
    "from collections import Counter\n",
    "from typing import Tuple\n",
    "\n",
    "  \n",
    "CSS2_COLOR_DICT = _get_hex_to_name_map(\"css2\")\n",
    "CSS2_COLOR_NAMES = list(CSS2_COLOR_DICT.values())\n",
    "\n",
    "def closest_color(requested_color: Tuple[int, int, int]) -> str:\n",
    "    \"\"\"\n",
    "    Given an RGB tuple, find the closest CSS2 color name based on Euclidean distance.\n",
    "    \n",
    "    Parameters:\n",
    "        requested_color (Tuple[int, int, int]): The RGB color tuple.\n",
    "        \n",
    "    Returns:\n",
    "        str: The name of the closest CSS2 color.\n",
    "    \"\"\"\n",
    "    min_distance = float('inf')\n",
    "    closest_name = None\n",
    "    for hex, name in CSS2_COLOR_DICT.items():\n",
    "        rgb = webcolors.hex_to_rgb(hex)\n",
    "        distance = sum((comp1 - comp2) ** 2 for comp1, comp2 in zip(requested_color, rgb))\n",
    "        if distance < min_distance:\n",
    "            min_distance = distance\n",
    "            closest_name = name\n",
    "    \n",
    "    return closest_name\n",
    "\n",
    "def get_css2_color_name(rgb_tuple: Tuple[int, int, int]) -> str:\n",
    "    \"\"\"\n",
    "    Convert an RGB tuple to its CSS2 color name.\n",
    "    If an exact match is not found, use the closest matching color.\n",
    "    \n",
    "    Parameters:\n",
    "        rgb_tuple (Tuple[int, int, int]): The RGB color tuple.\n",
    "        \n",
    "    Returns:\n",
    "        str: The CSS2 color name.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Attempt to get the CSS2 color name directly.\n",
    "        color_name = webcolors.rgb_to_name(rgb_tuple, \"css2\")\n",
    "    except ValueError:\n",
    "        # If there's no exact match, use the closest matching color.\n",
    "        color_name = closest_color(rgb_tuple)\n",
    "    \n",
    "    return color_name\n",
    "\n",
    "def image_color_breakdown(image_path: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Given the path to a PNG image, compute the percentage breakdown\n",
    "    of the CSS2 colors present in the image.\n",
    "    Transparent pixels (alpha == 0) are ignored.\n",
    "    \n",
    "    Parameters:\n",
    "        image_path (str): The path to the PNG image.\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame with columns:\n",
    "                      ['filename', 'aqua', 'black', 'blue', 'fuchsia', 'green', 'gray',\n",
    "                       'lime', 'maroon', 'navy', 'olive', 'purple', 'red', 'silver',\n",
    "                       'teal', 'white', 'yellow'].\n",
    "    \"\"\"\n",
    "    # Open the image in RGBA mode to handle transparency.\n",
    "    img = Image.open(image_path).convert('RGBA')\n",
    "    # Filter out pixels where the alpha channel is 0 (fully transparent).\n",
    "    pixels = [pixel for pixel in img.getdata() if pixel[3] != 0]\n",
    "    \n",
    "    if not pixels:\n",
    "        raise ValueError(\"No non-transparent pixels found in the image.\")\n",
    "    \n",
    "    total_pixels = len(pixels)\n",
    "    \n",
    "    # Count the occurrences of each allowed color.\n",
    "    color_counts = Counter()\n",
    "    for pixel in pixels:\n",
    "        rgb = pixel[:3]\n",
    "        color_name = get_css2_color_name(rgb)\n",
    "        color_counts[color_name] += 1\n",
    "    \n",
    "    # Prepare the breakdown dictionary with all allowed colors.\n",
    "    breakdown = {'filename': os.path.basename(image_path)}\n",
    "    for color in CSS2_COLOR_NAMES:\n",
    "        breakdown[color] = 0.0  # default 0%\n",
    "    \n",
    "    # Compute the percentage for each color that occurred.\n",
    "    for color, count in color_counts.items():\n",
    "        breakdown[color] = (count / total_pixels) * 100\n",
    "    \n",
    "    # Create the DataFrame with the columns in the required order.\n",
    "    columns = [\n",
    "        'filename', 'aqua', 'black', 'blue', 'fuchsia', 'green', 'gray',\n",
    "        'lime', 'maroon', 'navy', 'olive', 'purple', 'red', 'silver',\n",
    "        'teal', 'white', 'yellow'\n",
    "    ]\n",
    "    df = pd.DataFrame([breakdown], columns=columns)\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import webcolors\n",
    "import PIL\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "pkmn_img_colors = pd.read_csv(PKMN_COLORS_PATH, index_col=0)\n",
    "\n",
    "# # Create a dataframe of all test images\n",
    "# pkmn_img_colors = pd.DataFrame()\n",
    "\n",
    "# img_filenames = []\n",
    "\n",
    "# for pkmn_name in os.listdir(IMG_TEST_DIR):\n",
    "#     pkmn_folder = os.path.join(IMG_TEST_DIR, pkmn_name)\n",
    "#     if os.path.isdir(pkmn_folder):  # Check if it's a directory\n",
    "#         # Get all image files in the class folder\n",
    "#         images = [os.path.join(pkmn_folder, img) for img in os.listdir(pkmn_folder) if img.endswith('.png')]\n",
    "#         img_filenames.extend(images)\n",
    "#         for filename in images:\n",
    "#             temp_df = image_color_breakdown(filename)\n",
    "#             temp_df['Name'] = pkmn_name  # Add pkmn_name in a column called \"Name\"\n",
    "#             pkmn_img_colors = pd.concat([pkmn_img_colors, temp_df], ignore_index=True)\n",
    "#\n",
    "# pkmn_img_colors.to_csv(PKMN_COLORS_PATH, sep=\",\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import in-game statistics dataset\n",
    "pkmn_numbers = pd.read_csv(PKMN_STATS_PATH, encoding=\"utf-8\")\n",
    "\n",
    "# Drop rows that contain Pokemon to be ignored\n",
    "ignored_pkmn = pd.read_csv(IGNORED_PKMN_PATH, encoding=\"utf-8\", delimiter=\"\\t\")\n",
    "ignored_pkmn = ignored_pkmn.dropna(axis=0, subset=[\"Number\"])\n",
    "# print(f\"Ignored PKMN: {ignored_pkmn[\"Name\"].tolist()}\")\n",
    "\n",
    "pkmn_numbers = pkmn_numbers[~pkmn_numbers[\"Number\"].isin(ignored_pkmn[\"Number\"])]\n",
    "# print(f\"PKMN after dropping ignored: {pkmn_numbers.shape[0]}\")\n",
    "\n",
    "pkmn_numbers = pkmn_numbers.drop(labels=['Total', 'HP', 'Attack', 'Defense', 'Sp. Atk', 'Sp. Def', 'Speed', 'Generation', 'Legendary'], axis=1)\n",
    "pkmn_numbers[\"Name\"] = pkmn_numbers[\"Name\"].apply(lambda x: x.lower())\n",
    "\n",
    "# Add numbers to image data\n",
    "# print(f\"pkmn_numbers columns: {list(pkmn_numbers.columns)}\")\n",
    "# print(f\"pkmn_img_colors columns: {list(pkmn_img_colors.columns)}\")\n",
    "pkmn_img_data = pd.merge(pkmn_numbers, pkmn_img_colors, how=\"left\", left_on=[\"Name\", ], right_on=[\"Name\", ])\n",
    "\n",
    "pkmn_img_data = pkmn_img_data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Number       Name Type 1  Type 2          filename      aqua      black  \\\n",
      "0       1  bulbasaur  Grass  Poison   bulbasaur_1.png  0.319285  22.541507   \n",
      "1       1  bulbasaur  Grass  Poison  bulbasaur_10.png  0.000000  11.523438   \n",
      "2       1  bulbasaur  Grass  Poison  bulbasaur_11.png  0.000000  32.841328   \n",
      "3       1  bulbasaur  Grass  Poison  bulbasaur_12.png  0.000000  10.284424   \n",
      "4       1  bulbasaur  Grass  Poison  bulbasaur_13.png  0.000000  16.790771   \n",
      "\n",
      "   blue  fuchsia     green  ...      lime    maroon      navy      olive  \\\n",
      "0   0.0      0.0  1.660281  ...  0.127714  0.000000  0.127714  36.973180   \n",
      "1   0.0      0.0  0.000000  ...  0.000000  0.000000  0.000000   0.000000   \n",
      "2   0.0      0.0  4.797048  ...  0.067092  0.000000  0.000000   1.543106   \n",
      "3   0.0      0.0  3.942871  ...  0.000000  0.305176  0.000000   0.775146   \n",
      "4   0.0      0.0  0.000000  ...  0.000000  0.000000  0.000000   0.000000   \n",
      "\n",
      "     purple  red     silver       teal      white    yellow  \n",
      "0  0.000000  0.0   3.384419  27.905492   0.000000  1.085568  \n",
      "1  0.000000  0.0   7.244873   0.000000  67.761230  0.000000  \n",
      "2  0.000000  0.0  17.175444   3.488762  14.256961  0.000000  \n",
      "3  0.189209  0.0  10.968018   1.721191  53.887939  0.000000  \n",
      "4  0.000000  0.0  10.150146   0.000000  53.765869  0.000000  \n",
      "\n",
      "[5 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "print(pkmn_img_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train some kind of model on Pokemon color data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: AI usage statement, ChatGPT helped write the image color analysis functions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.1)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
